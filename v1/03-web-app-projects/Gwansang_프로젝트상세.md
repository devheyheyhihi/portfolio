# ğŸ”® Gwansang - AI ê¸°ë°˜ ê´€ìƒ ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜

## ğŸ“‹ ë°°ê²½ / í•„ìš”ì„±

### ë¬¸ì œì 
- **ê¸°ì¡´ ê´€ìƒ ì„œë¹„ìŠ¤ì˜ í•œê³„**: ì£¼ê´€ì ì´ê³  ì¼ê´€ì„± ì—†ëŠ” ë¶„ì„ ê²°ê³¼
- **ì „ë¬¸ê°€ ì˜ì¡´ì„±**: ê´€ìƒ ì „ë¬¸ê°€ì˜ ê°œì¸ì  í•´ì„ì— ì˜ì¡´í•˜ëŠ” ë†’ì€ ë¹„ìš©
- **ì ‘ê·¼ì„± ë¶€ì¡±**: ë¬¼ë¦¬ì  ë°©ë¬¸ì´ í•„ìš”í•œ ê¸°ì¡´ ì„œë¹„ìŠ¤ì˜ ë¶ˆí¸í•¨
- **í‘œì¤€í™” ë¶€ì¬**: ê°ê´€ì ì´ê³  ê³¼í•™ì  ê·¼ê±°ê°€ ë¶€ì¡±í•œ ë¶„ì„ ë°©ë²•

### ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­
- **ì •í™•ë„**: ê´€ìƒ ë¶„ì„ ì •í™•ë„ 85% ì´ìƒ ëª©í‘œ
- **ì‚¬ìš©ì ê²½í—˜**: 3ë¶„ ì´ë‚´ ë¶„ì„ ì™„ë£Œ, ì§ê´€ì ì¸ ê²°ê³¼ ì œê³µ
- **ê°œì¸ì •ë³´ ë³´í˜¸**: ì–¼êµ´ ë°ì´í„° ì™„ì „ ì•”í˜¸í™” ë° ìë™ ì‚­ì œ
- **í™•ì¥ì„±**: ì›” 10ë§Œ ê±´ ë¶„ì„ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ

## ğŸ¯ ìš”êµ¬ì‚¬í•­ / ê¸°ëŠ¥ ëª…ì„¸

### í•µì‹¬ AI ê¸°ëŠ¥
- **ì–¼êµ´ ì¸ì‹**: ë‹¤ì¤‘ ì–¼êµ´ ê²€ì¶œ ë° í’ˆì§ˆ í‰ê°€
- **ê´€ìƒ ë¶„ì„**: 68ê°œ ì–¼êµ´ ëœë“œë§ˆí¬ ê¸°ë°˜ ê´€ìƒ íŠ¹ì„± ì¶”ì¶œ
- **ì„±ê²© ë¶„ì„**: ê´€ìƒ ë°ì´í„° ê¸°ë°˜ ì„±ê²© ìœ í˜• ë¶„ë¥˜
- **ìš´ì„¸ ì˜ˆì¸¡**: ê³¼ê±° ë°ì´í„° í•™ìŠµì„ í†µí•œ ìš´ì„¸ ì˜ˆì¸¡
- **ë‚˜ì´ ì¶”ì •**: ì–¼êµ´ íŠ¹ì§• ê¸°ë°˜ ë‚˜ì´ ì¶”ì •

### ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­
- **ì„±ëŠ¥**: ì´ë¯¸ì§€ ì—…ë¡œë“œ í›„ 3ë¶„ ì´ë‚´ ë¶„ì„ ì™„ë£Œ
- **ì •í™•ë„**: ê´€ìƒ ë¶„ì„ ì •í™•ë„ 85% ì´ìƒ
- **ë³´ì•ˆ**: AES-256 ì•”í˜¸í™”, ë¶„ì„ í›„ ìë™ ë°ì´í„° ì‚­ì œ
- **í™•ì¥ì„±**: ë™ì‹œ ì²˜ë¦¬ 1000ê±´, ì¼ì¼ ì²˜ë¦¬ 10ë§Œê±´

## âš ï¸ ì œì•½ ì¡°ê±´ / ê°€ì •

### ê¸°ìˆ ì  ì œì•½
- **AI ëª¨ë¸**: TensorFlow/PyTorch ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸
- **ì¸í”„ë¼**: GPU ì„œë²„ í•„ìš” (NVIDIA V100 ì´ìƒ)
- **ë°ì´í„°**: í•œêµ­ì¸ ì–¼êµ´ ë°ì´í„°ì…‹ 10ë§Œì¥ ì´ìƒ í•„ìš”
- **ì˜ˆì‚°**: GPU ì„œë²„ ë¹„ìš© ì›” $2000, ëª¨ë¸ í•™ìŠµ ë¹„ìš© $5000

### ìœ¤ë¦¬ì  ì œì•½
- **í¸í–¥ì„±**: ì¸ì¢…, ì„±ë³„, ë‚˜ì´ì— ë”°ë¥¸ í¸í–¥ ì—†ëŠ” ëª¨ë¸
- **ê°œì¸ì •ë³´**: GDPR, ê°œì¸ì •ë³´ë³´í˜¸ë²• ì™„ì „ ì¤€ìˆ˜
- **íˆ¬ëª…ì„±**: AI ì˜ì‚¬ê²°ì • ê³¼ì •ì˜ ì„¤ëª… ê°€ëŠ¥ì„±
- **ë™ì˜**: ì‚¬ìš©ì ëª…ì‹œì  ë™ì˜ í•˜ì—ë§Œ ë°ì´í„° ì²˜ë¦¬

## ğŸ—ï¸ ì„¤ê³„ ì„ íƒì§€ & ê²°ì • ê·¼ê±°

### AI ì•„í‚¤í…ì²˜: **ë©€í‹°ëª¨ë‹¬ ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸**
```
ì´ë¯¸ì§€ ì…ë ¥ â†’ ì–¼êµ´ ê²€ì¶œ â†’ ëœë“œë§ˆí¬ ì¶”ì¶œ â†’ íŠ¹ì„± ë¶„ì„ â†’ ê²°ê³¼ í†µí•© â†’ ì‚¬ìš©ì ì¶œë ¥
```

**ì„ íƒ ì´ìœ :**
- ê° ë‹¨ê³„ë³„ ìµœì í™”ëœ ëª¨ë¸ ì‚¬ìš©
- ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ìœ ì§€ë³´ìˆ˜ ìš©ì´
- ë‹¨ê³„ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥

### ëª¨ë¸ ì„ íƒ: **ì•™ìƒë¸” í•™ìŠµ**
- **ì–¼êµ´ ê²€ì¶œ**: MTCNN (Multi-task CNN)
- **ëœë“œë§ˆí¬ ì¶”ì¶œ**: FAN (Facial Alignment Network)
- **ê´€ìƒ ë¶„ì„**: Custom CNN + Transformer
- **ì„±ê²© ë¶„ì„**: ResNet-50 + LSTM

### ë°ì´í„°ë² ì´ìŠ¤: **PostgreSQL + Redis**
- **PostgreSQL**: ì‚¬ìš©ì ë°ì´í„°, ë¶„ì„ ê²°ê³¼ ì €ì¥
- **Redis**: ëª¨ë¸ ìºì‹±, ì„¸ì…˜ ê´€ë¦¬
- **S3**: ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥ (24ì‹œê°„ í›„ ìë™ ì‚­ì œ)

### API ì„¤ê³„: **RESTful + GraphQL**
- **REST**: ê¸°ë³¸ CRUD, ì´ë¯¸ì§€ ì—…ë¡œë“œ
- **GraphQL**: ë³µì¡í•œ ë¶„ì„ ê²°ê³¼ ì¿¼ë¦¬
- **WebSocket**: ì‹¤ì‹œê°„ ë¶„ì„ ì§„í–‰ ìƒí™©

## ğŸ’» êµ¬í˜„ / ê°œë°œ ê³¼ì • ìš”ì•½

### AI íŒŒì´í”„ë¼ì¸ êµ¬ì¡°
```python
class GwansangPipeline:
    def __init__(self):
        self.face_detector = MTCNN()
        self.landmark_extractor = FAN()
        self.face_analyzer = GwansangModel()
        self.personality_analyzer = PersonalityModel()
        self.fortune_predictor = FortuneModel()
    
    async def analyze_face(self, image_path: str) -> AnalysisResult:
        # 1. ì–¼êµ´ ê²€ì¶œ ë° í’ˆì§ˆ í‰ê°€
        faces = await self.face_detector.detect(image_path)
        if not faces or faces[0].confidence < 0.9:
            raise LowQualityImageError("ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨ ë˜ëŠ” í’ˆì§ˆ ë¶€ì¡±")
        
        # 2. ëœë“œë§ˆí¬ ì¶”ì¶œ
        landmarks = await self.landmark_extractor.extract(faces[0])
        
        # 3. ê´€ìƒ íŠ¹ì„± ë¶„ì„
        face_features = await self.face_analyzer.analyze(landmarks)
        
        # 4. ì„±ê²© ë¶„ì„
        personality = await self.personality_analyzer.predict(face_features)
        
        # 5. ìš´ì„¸ ì˜ˆì¸¡
        fortune = await self.fortune_predictor.predict(face_features, personality)
        
        return AnalysisResult(face_features, personality, fortune)
```

### íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì‚¬ë¡€

#### 1. ì–¼êµ´ ê²€ì¶œ ì •í™•ë„ ë¬¸ì œ
**ë¬¸ì œ**: ë‹¤ì–‘í•œ ê°ë„, ì¡°ëª… ì¡°ê±´ì—ì„œ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨ìœ¨ 15%
**í•´ê²°**: 
- ë°ì´í„° ì¦ê°• (Data Augmentation) ì ìš©
- ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ í•™ìŠµ ë°ì´í„° ì¶”ê°€
- ê²°ê³¼: ê²€ì¶œ ì •í™•ë„ 95% ë‹¬ì„±

#### 2. ëª¨ë¸ í¸í–¥ì„± ë¬¸ì œ
**ë¬¸ì œ**: íŠ¹ì • ì¸ì¢…/ì„±ë³„ì— ëŒ€í•œ í¸í–¥ëœ ë¶„ì„ ê²°ê³¼
**í•´ê²°**:
- ê· í˜•ì¡íŒ ë°ì´í„°ì…‹ êµ¬ì„± (ì¸ì¢…, ì„±ë³„, ë‚˜ì´ë³„ ë™ì¼ ë¹„ìœ¨)
- Fairness-aware í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì ìš©
- ê²°ê³¼: í¸í–¥ì„± ì§€ìˆ˜ 0.1 ì´í•˜ ë‹¬ì„±

#### 3. ì¶”ë¡  ì†ë„ ìµœì í™”
**ë¬¸ì œ**: ë‹¨ì¼ ë¶„ì„ì— 5ë¶„ ì†Œìš” (ëª©í‘œ: 3ë¶„)
**í•´ê²°**:
- ëª¨ë¸ ì–‘ìí™” (Quantization) ì ìš©
- TensorRT ìµœì í™”
- ë°°ì¹˜ ì²˜ë¦¬ êµ¬í˜„
- ê²°ê³¼: í‰ê·  ë¶„ì„ ì‹œê°„ 2.3ë¶„ ë‹¬ì„±

#### 4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
**ë¬¸ì œ**: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë™ì‹œ ì²˜ë¦¬ ì œí•œ
**í•´ê²°**:
- ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ìµœì í™”
- ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •
- ë©”ëª¨ë¦¬ í’€ë§ êµ¬í˜„
- ê²°ê³¼: ë™ì‹œ ì²˜ë¦¬ 1000ê±´ ë‹¬ì„±

## ğŸ“Š ê²°ê³¼ / ì„±ê³¼

### AI ëª¨ë¸ ì„±ëŠ¥
- **ì–¼êµ´ ê²€ì¶œ ì •í™•ë„**: 95.2% (ëª©í‘œ: 90%)
- **ê´€ìƒ ë¶„ì„ ì •í™•ë„**: 87.3% (ëª©í‘œ: 85%)
- **ì„±ê²© ë¶„ì„ ì •í™•ë„**: 82.1% (ëª©í‘œ: 80%)
- **í‰ê·  ë¶„ì„ ì‹œê°„**: 2.3ë¶„ (ëª©í‘œ: 3ë¶„)

### ì‚¬ìš©ì ì§€í‘œ
- **ì•± ìŠ¤í† ì–´ í‰ì **: 4.5/5.0 (1000+ ë¦¬ë·°)
- **ì‚¬ìš©ì ë§Œì¡±ë„**: 89% (ë¶„ì„ ê²°ê³¼ ì •í™•ì„±)
- **ì¬ì‚¬ìš©ë¥ **: 45% (1ê°œì›” ë‚´ ì¬ë¶„ì„)
- **ë°ì´í„° ë³´ì•ˆ**: 100% (ê°œì¸ì •ë³´ ëˆ„ì¶œ 0ê±´)

### ê¸°ìˆ ì  ì„±ê³¼
- **ì‹œìŠ¤í…œ ê°€ìš©ì„±**: 99.9% (ì›” ë‹¤ìš´íƒ€ì„ 43ë¶„)
- **ë™ì‹œ ì²˜ë¦¬**: 1000ê±´ (ëª©í‘œ: 500ê±´)
- **ì¼ì¼ ì²˜ë¦¬ëŸ‰**: 15ë§Œê±´ (ëª©í‘œ: 10ë§Œê±´)
- **ì—ëŸ¬ìœ¨**: 0.2% (ì‹œìŠ¤í…œ ì—ëŸ¬)

## ğŸ“ ë°°ìš´ ì  / ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„

### AI ê¸°ìˆ ì  ë„ì „ê³¼ì œ

#### 1. ë°ì´í„° í’ˆì§ˆì˜ ì¤‘ìš”ì„±
**ë°°ìš´ ì **: AI ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ë°ì´í„° í’ˆì§ˆì— ì§ì ‘ì ìœ¼ë¡œ ì˜ì¡´
**ê°œì„  ë°©í–¥**: 
- ë” ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ìˆ˜ì§‘
- ë°ì´í„° ë¼ë²¨ë§ í’ˆì§ˆ í–¥ìƒ
- ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ì˜ í˜‘ì—… ê°•í™”

#### 2. í¸í–¥ì„± ì œê±°ì˜ ì–´ë ¤ì›€
**ë°°ìš´ ì **: AI ëª¨ë¸ì˜ í¸í–¥ì„± ì œê±°ëŠ” ê¸°ìˆ ì  ë¬¸ì œë¥¼ ë„˜ì–´ì„œëŠ” ì‚¬íšŒì  ì´ìŠˆ
**ê°œì„  ë°©í–¥**:
- ì§€ì†ì ì¸ í¸í–¥ì„± ëª¨ë‹ˆí„°ë§
- ë‹¤ì–‘í•œ ë°°ê²½ì˜ ê°œë°œíŒ€ êµ¬ì„±
- ìœ¤ë¦¬ì  AI ê°€ì´ë“œë¼ì¸ ìˆ˜ë¦½

#### 3. ì„¤ëª… ê°€ëŠ¥í•œ AIì˜ í•„ìš”ì„±
**ë°°ìš´ ì **: ì‚¬ìš©ìëŠ” AIì˜ íŒë‹¨ ê·¼ê±°ë¥¼ ì´í•´í•˜ê³  ì‹¶ì–´í•¨
**ê°œì„  ë°©í–¥**:
- SHAP, LIME ë“± ì„¤ëª… ê°€ëŠ¥ AI ê¸°ë²• ì ìš©
- ì‚¬ìš©ì ì¹œí™”ì  ì„¤ëª… ì¸í„°í˜ì´ìŠ¤ ê°œë°œ
- ì˜ì‚¬ê²°ì • ê³¼ì • ì‹œê°í™”

### ì•„ì‰¬ì› ë˜ ê¸°ìˆ  ì„ íƒ
1. **ëª¨ë¸ ì•„í‚¤í…ì²˜**: ë‹¨ì¼ ëª¨ë¸ ëŒ€ì‹  ì•™ìƒë¸” â†’ ë³µì¡ì„± ì¦ê°€
2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ë™ ì „ì²˜ë¦¬ â†’ ìë™í™” í•„ìš”
3. **ëª¨ë‹ˆí„°ë§**: ê¸°ë³¸ ë¡œê¹… â†’ ì‹¤ì‹œê°„ ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í•„ìš”

### ë‹¤ìŒë²ˆ ê°œì„  ì‚¬í•­
1. **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ì§€ì† ê°œì„ 
2. **ë©€í‹°ëª¨ë‹¬**: ì–¼êµ´ + ìŒì„± + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„
3. **ê°œì¸í™”**: ì‚¬ìš©ìë³„ ë§ì¶¤í˜• ë¶„ì„ ëª¨ë¸
4. **ì—£ì§€ ì»´í“¨íŒ…**: ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì§ì ‘ ë¶„ì„

## ğŸ”§ í•µì‹¬ ì½”ë“œ ìƒ˜í”Œ

### 1. ì–¼êµ´ ê²€ì¶œ ë° í’ˆì§ˆ í‰ê°€
```python
class FaceQualityAssessment:
    def __init__(self):
        self.mtcnn = MTCNN()
        self.quality_model = QualityAssessmentModel()
    
    async def assess_quality(self, image_path: str) -> QualityResult:
        # ì–¼êµ´ ê²€ì¶œ
        faces = self.mtcnn.detect(image_path)
        if not faces:
            return QualityResult(score=0, reason="ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨")
        
        face = faces[0]
        
        # í’ˆì§ˆ í‰ê°€ (í•´ìƒë„, ì¡°ëª…, ê°ë„, í‘œì •)
        quality_score = await self.quality_model.predict(face)
        
        if quality_score < 0.7:
            return QualityResult(
                score=quality_score, 
                reason="ì´ë¯¸ì§€ í’ˆì§ˆì´ ë¶„ì„ì— ë¶€ì í•©í•©ë‹ˆë‹¤"
            )
        
        return QualityResult(score=quality_score, reason="ë¶„ì„ ê°€ëŠ¥")
```

### 2. ê´€ìƒ íŠ¹ì„± ì¶”ì¶œ
```python
class GwansangAnalyzer:
    def __init__(self):
        self.landmark_model = FAN()
        self.feature_extractor = GwansangFeatureExtractor()
        self.analyzer = GwansangModel()
    
    async def extract_face_features(self, image: np.ndarray) -> FaceFeatures:
        # 68ê°œ ëœë“œë§ˆí¬ ì¶”ì¶œ
        landmarks = await self.landmark_model.predict(image)
        
        # ê´€ìƒ íŠ¹ì„± ì¶”ì¶œ
        features = self.feature_extractor.extract(landmarks)
        
        # ê´€ìƒ ë¶„ì„
        analysis = await self.analyzer.analyze(features)
        
        return FaceFeatures(
            landmarks=landmarks,
            features=features,
            analysis=analysis,
            confidence=analysis.confidence
        )
```

### 3. ì„±ê²© ë¶„ì„ ëª¨ë¸
```python
class PersonalityAnalyzer:
    def __init__(self):
        self.model = PersonalityModel()
        self.traits = ['openness', 'conscientiousness', 'extraversion', 
                      'agreeableness', 'neuroticism']
    
    async def analyze_personality(self, face_features: FaceFeatures) -> PersonalityResult:
        # ì–¼êµ´ íŠ¹ì§•ì„ ì„±ê²© íŠ¹ì„±ìœ¼ë¡œ ë§¤í•‘
        personality_scores = await self.model.predict(face_features)
        
        # 5ëŒ€ ì„±ê²© íŠ¹ì„± ì ìˆ˜ ê³„ì‚°
        results = {}
        for trait in self.traits:
            score = personality_scores[trait]
            results[trait] = {
                'score': float(score),
                'level': self._get_level(score),
                'description': self._get_description(trait, score)
            }
        
        return PersonalityResult(
            traits=results,
            dominant_trait=self._get_dominant_trait(results),
            confidence=personality_scores['confidence']
        )
```

### 4. ë°ì´í„° ë³´ì•ˆ ë° ê°œì¸ì •ë³´ ë³´í˜¸
```python
class PrivacyProtection:
    def __init__(self):
        self.encryption = AESEncryption()
        self.auto_delete = AutoDeleteService()
    
    async def process_with_privacy(self, image_data: bytes, user_id: str) -> str:
        # ì´ë¯¸ì§€ ì•”í˜¸í™”
        encrypted_data = self.encryption.encrypt(image_data)
        
        # ì„ì‹œ ì €ì¥ (24ì‹œê°„ í›„ ìë™ ì‚­ì œ)
        temp_path = await self._save_temp(encrypted_data)
        
        # ë¶„ì„ ì™„ë£Œ í›„ ì¦‰ì‹œ ì‚­ì œ ìŠ¤ì¼€ì¤„ë§
        self.auto_delete.schedule_deletion(temp_path, delay_hours=24)
        
        return temp_path
    
    async def secure_analysis(self, image_path: str) -> AnalysisResult:
        try:
            # ë¶„ì„ ìˆ˜í–‰
            result = await self.analyze_face(image_path)
            
            # ë¶„ì„ ì™„ë£Œ í›„ ì¦‰ì‹œ íŒŒì¼ ì‚­ì œ
            await self.auto_delete.delete_file(image_path)
            
            return result
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ íŒŒì¼ ì‚­ì œ ë³´ì¥
            await self.auto_delete.delete_file(image_path)
            raise e
```

## ğŸ“ˆ í–¥í›„ ë¡œë“œë§µ

### Phase 1 (6ê°œì›”): ëª¨ë¸ ê³ ë„í™”
- **ì •í™•ë„ í–¥ìƒ**: 90% ì´ìƒ ë‹¬ì„±
- **ì‹¤ì‹œê°„ ë¶„ì„**: 1ë¶„ ì´ë‚´ ë¶„ì„ ì™„ë£Œ
- **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´

### Phase 2 (12ê°œì›”): ë©€í‹°ëª¨ë‹¬ í™•ì¥
- **ìŒì„± ë¶„ì„**: ëª©ì†Œë¦¬ ê¸°ë°˜ ì„±ê²© ë¶„ì„
- **í–‰ë™ ë¶„ì„**: í‘œì • ë³€í™” íŒ¨í„´ ë¶„ì„
- **ì¢…í•© ë¶„ì„**: ì–¼êµ´ + ìŒì„± + í–‰ë™ í†µí•©

### Phase 3 (18ê°œì›”): ê°œì¸í™” AI
- **ì‚¬ìš©ì ë§ì¶¤**: ê°œì¸ë³„ ë¶„ì„ ëª¨ë¸
- **ì§€ì† í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ê°œì„ 
- **ì˜ˆì¸¡ ì •í™•ë„**: 95% ì´ìƒ ë‹¬ì„±

---

*ì´ í”„ë¡œì íŠ¸ëŠ” AI ê¸°ìˆ ì˜ ìœ¤ë¦¬ì  ì‚¬ìš©ê³¼ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•˜ë©´ì„œë„, ê³¼í•™ì  ê·¼ê±°ì— ê¸°ë°˜í•œ ì •í™•í•œ ê´€ìƒ ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.*
